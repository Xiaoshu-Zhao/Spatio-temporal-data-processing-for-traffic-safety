{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"traffic-model-classifier.ipynb","provenance":[{"file_id":"1Ot1Y-c9xsJjCfTjdsvZQMsaUWcmXsAzb","timestamp":1625124346252}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9d59ff23c23b4eb7b6631dc635d84960":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_263ff7b7708049e2b83ccf8a0da5e7b5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c1209361f4a14d348a0691796fd01393","IPY_MODEL_76dc8648a15841b7b87168f563436a29"]}},"263ff7b7708049e2b83ccf8a0da5e7b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1209361f4a14d348a0691796fd01393":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6b63578f6ae148eebb0f0106daff723f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51649035c35f4987bef99055dd9cf084"}},"76dc8648a15841b7b87168f563436a29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71d1db9bd3b346dbb3e458ff18f0535e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:02&lt;00:00, 111kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47900785812343269ae484aab764f2f9"}},"6b63578f6ae148eebb0f0106daff723f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"51649035c35f4987bef99055dd9cf084":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71d1db9bd3b346dbb3e458ff18f0535e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"47900785812343269ae484aab764f2f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6dee2e899f414c1c817fafb8e1d2ea2a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6579412ce1bb40ca97be21504c62fb21","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f094aaad87ce4286979d2102200557da","IPY_MODEL_ffdbe3b68fa941f19afeb1f7419d1736"]}},"6579412ce1bb40ca97be21504c62fb21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f094aaad87ce4286979d2102200557da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ba9419369aec47caa0f94693757052e1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f86346e4c38648dea47000f767e9bbab"}},"ffdbe3b68fa941f19afeb1f7419d1736":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_95f560a7281049438f56c2844f274d50","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 34.4B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c17bd3206bf24e299d2fcf44d3bb4ef0"}},"ba9419369aec47caa0f94693757052e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f86346e4c38648dea47000f767e9bbab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95f560a7281049438f56c2844f274d50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c17bd3206bf24e299d2fcf44d3bb4ef0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0fe42013b24b478eacca1e9449b4a1b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_61b4425f66814b36a4d02099b10b9199","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9d9bd916910343a98c0d74d82fc69638","IPY_MODEL_5d2576c33e2a492aaa0769ab797b6085"]}},"61b4425f66814b36a4d02099b10b9199":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d9bd916910343a98c0d74d82fc69638":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_22d068f424a84c448515752f2279c2c8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da18807a32ff4737b3ed21db0972f017"}},"5d2576c33e2a492aaa0769ab797b6085":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3b420a465e644cf98ecff7079d699c1c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 2.28MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79cf077c0a9c4a479d87596269545d11"}},"22d068f424a84c448515752f2279c2c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"da18807a32ff4737b3ed21db0972f017":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b420a465e644cf98ecff7079d699c1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79cf077c0a9c4a479d87596269545d11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"jdSBX7XS94Cj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625716762825,"user_tz":240,"elapsed":17254,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"2f2bfa21-b29e-4dbb-8333-0f1fa43c71a8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKafizRU-a80","executionInfo":{"status":"ok","timestamp":1625716765971,"user_tz":240,"elapsed":122,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"cc7194b4-6802-4264-8769-4f4f0ab5bef9"},"source":["cd /content/drive/MyDrive/Spatio-temporal data processing for traffic safety/nlp"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Spatio-temporal data processing for traffic safety/nlp\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QH_DuXWR-dC5","executionInfo":{"status":"ok","timestamp":1625716769272,"user_tz":240,"elapsed":392,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"c2aababd-7fe9-4fbf-e28a-beedd455df60"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sample_twitter_subway.csv\t\t  subway_binary_model.pt\n","sentiment-traffic-model-classifier.ipynb  traffic-model-classifier.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mvniYHTRhwpz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625716794834,"user_tz":240,"elapsed":19830,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"3be97042-dedb-4a58-8a51-26e31b137f0e"},"source":["!pip install unidecode\n","!pip install tweet-preprocessor\n","!pip install contractions\n","!pip install word2number\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n","\r\u001b[K     |█▍                              | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 20.9MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 16.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 15.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 10.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 8.4MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.2.0\n","Collecting tweet-preprocessor\n","  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n","Installing collected packages: tweet-preprocessor\n","Successfully installed tweet-preprocessor-0.6.0\n","Collecting contractions\n","  Downloading https://files.pythonhosted.org/packages/93/f4/0ec4a458e4368cc3be2c799411ecf0bc961930e566dadb9624563821b3a6/contractions-0.0.52-py2.py3-none-any.whl\n","Collecting textsearch>=0.0.21\n","  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n","Collecting pyahocorasick\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/c2/eae730037ae1cbbfaa229d27030d1d5e34a1e41114b21447d1202ae9c220/pyahocorasick-1.4.2.tar.gz (321kB)\n","\u001b[K     |████████████████████████████████| 327kB 7.5MB/s \n","\u001b[?25hCollecting anyascii\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/14/666cd44bf53f36a961544af592cb5c5c800013f9c51a4745af8d7c17362a/anyascii-0.2.0-py3-none-any.whl (283kB)\n","\u001b[K     |████████████████████████████████| 286kB 13.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85396 sha256=ab301bd9c010d49fef73b249404f1f02dc81b03f884c36fee5f9f7ab54f8918c\n","  Stored in directory: /root/.cache/pip/wheels/3a/03/34/77e3ece0bba8b86bfac88a79f923b36d805cad63caeba38842\n","Successfully built pyahocorasick\n","Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n","Collecting word2number\n","  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n","Building wheels for collected packages: word2number\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-cp37-none-any.whl size=5584 sha256=dc632f179a0be72f4f00d38ec963722de1d2ef16723c410aa271486e6cfa62c6\n","  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n","Successfully built word2number\n","Installing collected packages: word2number\n","Successfully installed word2number-1.1\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 50.9MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 48.0MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YFUrq49gilC7"},"source":["import spacy\n","import pandas as pd\n","import unidecode\n","from word2number import w2n\n","import contractions\n","import preprocessor as p\n","import numpy as np\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_XY898F64_8"},"source":["sample_data_path = 'sample_twitter_subway.csv'\n","df_raw = pd.read_csv(sample_data_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6V3UXTi68CQO"},"source":["# Preprocess\n","\n","## Text Cleaning\n","\n","Manual Elimination & Text Cleaning\n","\n","Remove Retweets 'RT @' from the dataset, to lowercase and Remove all 'Uber Eats' records\n"]},{"cell_type":"code","metadata":{"id":"Hb6Wf1qvRrPM"},"source":["def remove_manually(df, word_list=['uber eats']):\n","    df = df[~df[\"txt\"].str.contains(\"RT @\")]\n","    df[\"txt\"] = df[\"txt\"].str.lower()\n","    for word in word_list:\n","        df = df[~df[\"txt\"].str.contains(word)]\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rf6WAVCaTjWe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625716816452,"user_tz":240,"elapsed":134,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"c02d5ce4-8db1-402e-bd08-0018088bd73e"},"source":["df = remove_manually(df_raw)\n","df.replace({'label': {'n':0, 'y':1}}, inplace=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"xWGZjqXn65XM","executionInfo":{"status":"ok","timestamp":1625716819059,"user_tz":240,"elapsed":124,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"1a3b6a84-27c5-49b5-9c0a-c1f0c1c70f13"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>txt</th>\n","      <th>label</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>dancers often focus on training flexible hamst...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>@evanplewis after 14.5 months of silence, subw...</td>\n","      <td>1</td>\n","      <td>h</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>@zer0access @patriottakes trump one-upped jesu...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>@ashindestad my mate used to say taking the tr...</td>\n","      <td>1</td>\n","      <td>h</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>@laurenjohnston after 14.5 months of silence, ...</td>\n","      <td>1</td>\n","      <td>h</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>344</td>\n","      <td>do not go where the path may lead, go instead ...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>345</td>\n","      <td>jamaica–179 st/forest hills–71 av/145 st/norwo...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>346</td>\n","      <td>jamaica–179 st/forest hills–71 av/145 st/norwo...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>348</td>\n","      <td>@pingkind my expected path...the little top in...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>329</th>\n","      <td>349</td>\n","      <td>@tajh256 @boomifgc best of luck to yah man, ma...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>215 rows × 4 columns</p>\n","</div>"],"text/plain":["     Unnamed: 0  ... sentiment\n","3             3  ...       NaN\n","9             9  ...         h\n","16           16  ...       NaN\n","17           17  ...         h\n","19           19  ...         h\n","..          ...  ...       ...\n","325         344  ...       NaN\n","326         345  ...       NaN\n","327         346  ...       NaN\n","328         348  ...       NaN\n","329         349  ...       NaN\n","\n","[215 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"W5ZN0gL9RqpP"},"source":["Procedure\n","1.   Convert Accented Characters\n","2.   Expand Contractions\n","3.   Clean Text (using [tweet-preprocessor](https://github.com/s/preprocessor) package)\n","4.   Tokenize\n","\n"]},{"cell_type":"code","metadata":{"id":"nYEODQLv8Izp"},"source":["# https://towardsdatascience.com/nlp-text-preprocessing-a-practical-guide-and-template-d80874676e79\n","import en_core_web_sm\n","nlp = en_core_web_sm.load()\n","\n","# exclude words from spacy stopwords list\n","deselect_stop_words = ['no', 'not']\n","for w in deselect_stop_words:\n","    nlp.vocab[w].is_stop = False\n","\n","p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.HASHTAG, p.OPT.EMOJI, p.OPT.SMILEY)\n","\n","\n","def remove_accented_chars(text):\n","    \"\"\"\n","    remove accented characters from text, e.g. café\n","    \"\"\"\n","    text = unidecode.unidecode(text)\n","    return text\n","\n","def expand_contractions(text):\n","    \"\"\"\n","    expand shortened words, e.g. don't to do not\n","    \"\"\"\n","    text = contractions.fix(text)\n","    return text\n","\n","def clean_txt(target_text):\n","\n","    target_text = remove_accented_chars(target_text)\n","    target_text = expand_contractions(target_text)\n","    target_text = p.clean(target_text)\n","\n","    doc = nlp(target_text)\n","    clean_text = []\n","    for token in doc:\n","        flag = True\n","        edit = token.text\n","        # remove stop words\n","        if token.is_stop and token.pos_ != 'NUM': \n","            flag = False\n","        # remove punctuations\n","        if  token.pos_ == 'PUNCT' and flag == True: \n","            flag = False\n","        # remove special characters\n","        if  token.pos_ == 'SYM' and flag == True: \n","            flag = False\n","        # remove numbers\n","        if (token.pos_ == 'NUM' or token.text.isnumeric()) and flag == True:\n","            flag = False\n","        # convert number words to numeric numbers\n","        if token.pos_ == 'NUM' and flag == True:\n","            edit = w2n.word_to_num(token.text)\n","        # convert tokens to base form\n","        elif token.lemma_ != \"-PRON-\" and flag == True:\n","            edit = token.lemma_\n","        # append tokens edited and not removed to list \n","        if edit != \"\" and flag == True:\n","            clean_text.append(edit)\n","            \n","    return \" \".join(clean_text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k0SMIuaaqoPL"},"source":["## Word Embedding\n","\n"]},{"cell_type":"code","metadata":{"id":"0tXbw__xpWrt","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["9d59ff23c23b4eb7b6631dc635d84960","263ff7b7708049e2b83ccf8a0da5e7b5","c1209361f4a14d348a0691796fd01393","76dc8648a15841b7b87168f563436a29","6b63578f6ae148eebb0f0106daff723f","51649035c35f4987bef99055dd9cf084","71d1db9bd3b346dbb3e458ff18f0535e","47900785812343269ae484aab764f2f9","6dee2e899f414c1c817fafb8e1d2ea2a","6579412ce1bb40ca97be21504c62fb21","f094aaad87ce4286979d2102200557da","ffdbe3b68fa941f19afeb1f7419d1736","ba9419369aec47caa0f94693757052e1","f86346e4c38648dea47000f767e9bbab","95f560a7281049438f56c2844f274d50","c17bd3206bf24e299d2fcf44d3bb4ef0","0fe42013b24b478eacca1e9449b4a1b3","61b4425f66814b36a4d02099b10b9199","9d9bd916910343a98c0d74d82fc69638","5d2576c33e2a492aaa0769ab797b6085","22d068f424a84c448515752f2279c2c8","da18807a32ff4737b3ed21db0972f017","3b420a465e644cf98ecff7079d699c1c","79cf077c0a9c4a479d87596269545d11"]},"executionInfo":{"status":"ok","timestamp":1625716833121,"user_tz":240,"elapsed":6722,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"eed25836-e878-4402-dfec-0b7f9f54bc37"},"source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d59ff23c23b4eb7b6631dc635d84960","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6dee2e899f414c1c817fafb8e1d2ea2a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fe42013b24b478eacca1e9449b4a1b3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ME_UuKV0uDFE"},"source":["MAX_LEN = 110\n","def preprocessing_for_bert(data):\n","    \"\"\"Perform required preprocessing steps for pretrained BERT.\n","    @param    data (np.array): Array of texts to be processed.\n","    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n","    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n","                  tokens should be attended to by the model.\n","    \"\"\"\n","    # Create empty lists to store outputs\n","    input_ids = []\n","    attention_masks = []\n","\n","    # For every sentence...\n","    for sent in data:\n","        # `encode_plus` will:\n","        #    (1) Tokenize the sentence\n","        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n","        #    (3) Truncate/Pad sentence to max length\n","        #    (4) Map tokens to their IDs\n","        #    (5) Create attention mask\n","        #    (6) Return a dictionary of outputs\n","        encoded_sent = tokenizer.encode_plus(\n","            text=clean_txt(sent),  # Preprocess sentence\n","            add_special_tokens = True,        # Add `[CLS]` and `[SEP]`\n","            max_length= MAX_LEN,                  # Max length to truncate/pad\n","            pad_to_max_length=True,         # Pad sentence to max length\n","            #return_tensors='pt',           # Return PyTorch tensor\n","            return_attention_mask=True      # Return attention mask\n","            )\n","        # Add the outputs to the lists\n","        input_ids.append(encoded_sent.get('input_ids'))\n","        attention_masks.append(encoded_sent.get('attention_mask'))\n","\n","    # Convert lists to tensors\n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","\n","    return input_ids, attention_masks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xRyHd6JZhltN"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"GEAXarzXhXWY"},"source":["y = df.label\n","X = df.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aey_Xl12hlCc"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val =\\\n","    train_test_split(X, y, test_size = 0.3, random_state=2021)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5xdddFQiwlm"},"source":["import torch\n","cuda = torch.device('cuda')\n","device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LSkG_fy-xqBu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625716847761,"user_tz":240,"elapsed":2382,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"a19d4ae7-1caf-4a39-d26f-d9971fbb6356"},"source":["train_inputs, train_masks = preprocessing_for_bert(X_train)\n","val_inputs, val_masks = preprocessing_for_bert(X_val)\n","\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train.to_numpy())\n","val_labels = torch.tensor(y_val.to_numpy())\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 16\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2xqVRwOIjR87"},"source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel, AdamW, get_linear_schedule_with_warmup\n","\n","# Create the BertClassfier class\n","class BertClassifier(nn.Module):\n","\n","    def __init__(self, freeze_bert=False):\n","\n","        super(BertClassifier, self).__init__()\n","        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n","        D_in, H = 768, 50\n","\n","        # Instantiate BERT model\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","\n","        #Instantiate an one-layer feed-forward classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(D_in, 60),\n","            nn.Dropout(0.2),\n","            nn.Tanh(),\n","            nn.Linear(60, 1),\n","            nn.Sigmoid()\n","        )\n","        # self.classifier = nn.Sequential(\n","        #    nn.Linear(D_in, 1),\n","        #    nn.Sigmoid()\n","        # )\n","\n","        # Freeze the BERT model\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","        \n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"\n","\n","        \"\"\"\n","        # Feed input to BERT\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        \n","        # Extract the last hidden state of the token `[CLS]` for classification task\n","        last_hidden_state_cls = outputs[0][:, 0, :]\n","\n","        # Feed input to classifier to compute logits\n","        logits = self.classifier(last_hidden_state_cls)\n","\n","        return logits\n","\n","def initialize_model(epochs=4):\n","    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n","    \"\"\"\n","    # Instantiate Bert Classifier\n","    bert_classifier = BertClassifier(freeze_bert=False)\n","\n","    # Tell PyTorch to run the model on GPU\n","    bert_classifier.to(device)\n","\n","    # Create the optimizer\n","    optimizer = AdamW(bert_classifier.parameters(),\n","                      lr=1e-5,    # Default learning rate\n","                      eps=1e-5,    # Default epsilon value\n","                      weight_decay= 1)\n","\n","    # Total number of training steps\n","    total_steps = len(train_dataloader) * epochs\n","    print('total steps {}'.format(total_steps))\n","\n","    # Set up the learning rate scheduler\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","    return bert_classifier, optimizer, scheduler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e_Vt8EZMjsPk"},"source":["import random\n","import time\n","\n","# Specify loss function\n","criterion = nn.BCELoss().to(device)\n","\n","def set_seed(seed_value=42):\n","    \"\"\"Set seed for reproducibility.\n","    \"\"\"\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","\n","def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n","    \"\"\"Train the BertClassifier model.\n","    \"\"\"\n","    # Start training loop\n","    print(\"Start training...\\n\")\n","    for epoch_i in range(epochs):\n","        # =======================================\n","        #               Training\n","        # =======================================\n","        # Print the header of the result table\n","        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Train Acc':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n","        print(\"-\"*80)\n","\n","        # Measure the elapsed time of each epoch\n","        t0_epoch, t0_batch = time.time(), time.time()\n","\n","        # Reset tracking variables at the beginning of each epoch\n","        total_loss, batch_loss, batch_counts = 0, 0, 0\n","\n","        # Put the model into the training mode\n","        model.train()\n","\n","        # For each batch of training data...\n","        for step, batch in enumerate(train_dataloader):\n","            batch_counts +=1\n","            # Load batch to GPU\n","            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","            # Zero out any previously calculated gradients\n","            model.zero_grad()\n","\n","            # Perform a forward pass. This will return logits.\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","            # Compute loss and accumulate the loss values\n","            b_labels = b_labels.unsqueeze(1)\n","            # print(logits)\n","            # print(b_labels)\n","            loss = criterion(logits.double(), b_labels.double())\n","            # print(loss)\n","            batch_loss += loss.item()\n","            total_loss += loss.item()\n","\n","            # Perform a backward pass to calculate gradients\n","            loss.backward()\n","\n","            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            # Update parameters and the learning rate\n","            optimizer.step()\n","            scheduler.step()\n","\n","            # Print the loss values and time elapsed for every 20 batches\n","            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n","                # Calculate time elapsed for 20 batches\n","                time_elapsed = time.time() - t0_batch\n","\n","                # Print training results\n","                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {'-':^9} | {time_elapsed:^9.2f}\")\n","\n","                # Reset batch tracking variables\n","                batch_loss, batch_counts = 0, 0\n","                t0_batch = time.time()\n","\n","        # Calculate the average loss over the entire training data\n","        avg_train_loss = total_loss / len(train_dataloader)\n","\n","        print(\"-\"*80)\n","        # =======================================\n","        #               Evaluation\n","        # =======================================\n","        if evaluation == True:\n","            # After the completion of each training epoch, measure the model's performance\n","            # on our validation set.\n","            val_loss, val_accuracy = evaluate(model, val_dataloader)\n","            train_acc = evaluate(model, train_dataloader)[1]\n","            # Print performance over the entire training data\n","            time_elapsed = time.time() - t0_epoch\n","            \n","            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {train_acc:^9.2f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n","            print(\"-\"*80)\n","        print(\"\\n\")\n","    \n","    torch.save(model.state_dict(), '/content/drive/MyDrive/Spatio-temporal data processing for traffic safety/nlp/subway_binary_model.pt')\n","    \n","\n","    print(\"Training complete!\")\n","\n","\n","def evaluate(model, val_dataloader):\n","    \"\"\"After the completion of each training epoch, measure the model's performance\n","    on our validation set.\n","    \"\"\"\n","    # Put the model into the evaluation mode. The dropout layers are disabled during\n","    # the test time.\n","    model.eval()\n","\n","    # Tracking variables\n","    val_accuracy = []\n","    val_loss = []\n","\n","    # For each batch in our validation set...\n","    for batch in val_dataloader:\n","        # Load batch to GPU\n","        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","        # Compute logits\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","        # Compute loss\n","        b_labels = b_labels.unsqueeze(1)\n","        loss = criterion(logits.double(), b_labels.double())\n","        val_loss.append(loss.item())\n","\n","        # Get the predictions\n","\n","        preds = logits >= 0.5\n","\n","        # Calculate the accuracy rate\n","        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n","        val_accuracy.append(accuracy)\n","\n","    # Compute the average accuracy and loss over the validation set.\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_accuracy)\n","\n","    return val_loss, val_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":926},"id":"BrNWJWt-jt-z","executionInfo":{"status":"error","timestamp":1625717052597,"user_tz":240,"elapsed":18172,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"441c14ae-78fe-404a-cbda-0dade1b7afa7"},"source":["set_seed(12)    # Set seed for reproducibility\n","bert_classifier, optimizer, scheduler = initialize_model(epochs=20)\n","print('initialized')\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=10, evaluation = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["total steps 200\n","initialized\n","Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  | Train Acc  |  Val Acc  |  Elapsed \n","--------------------------------------------------------------------------------\n","   1    |    9    |   0.661199   |     -      |     -     |     -     |   3.06   \n","--------------------------------------------------------------------------------\n","   1    |    -    |   0.661199   |  0.622520  |   71.67   |   76.25   |   4.54   \n","--------------------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  | Train Acc  |  Val Acc  |  Elapsed \n","--------------------------------------------------------------------------------\n","   2    |    9    |   0.624942   |     -      |     -     |     -     |   3.00   \n","--------------------------------------------------------------------------------\n","   2    |    -    |   0.624942   |  0.593603  |   73.75   |   76.25   |   4.52   \n","--------------------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  | Train Acc  |  Val Acc  |  Elapsed \n","--------------------------------------------------------------------------------\n","   3    |    9    |   0.608989   |     -      |     -     |     -     |   3.04   \n","--------------------------------------------------------------------------------\n","   3    |    -    |   0.608989   |  0.563802  |   71.67   |   76.25   |   4.58   \n","--------------------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  | Train Acc  |  Val Acc  |  Elapsed \n","--------------------------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-543f4a29e3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'initialized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-617fbe2101a5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, evaluation)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# Update parameters and the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             raise RuntimeError(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"vViHkMjpnloM","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1625158467985,"user_tz":240,"elapsed":131,"user":{"displayName":"Xiaoshu Zhao","photoUrl":"","userId":"04362737402921253975"}},"outputId":"fc7faa12-7210-46b6-baa0-2c74d2b737b5"},"source":["pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Spatio-temporal data processing for traffic safety/nlp'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"fdPPDLglptJ-"},"source":["!export CUDA_LAUNCH_BLOCKING=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dtys9mMnptr-"},"source":["y.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iVB7cZcAp0or"},"source":[""],"execution_count":null,"outputs":[]}]}